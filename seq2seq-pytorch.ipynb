{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2INwUIhl67Rq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import spacy\n",
        "\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchtext.legacy.datasets import Multi30k\n",
        "from torchtext.legacy.data import Field, BucketIterator\n",
        "from torchtext.data.metrics import bleu_score"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNJ1GplIvYQU"
      },
      "source": [
        "MODEL_STORE_PATH = \"NLP/NMT/Seq2Seq/Seq2Seq\""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXW34QrH7GJ9",
        "outputId": "08d78769-4e09-4216-ada1-a9c1828dcb04"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Notebook is running on\", device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Notebook is running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDiDWP_N7DOt"
      },
      "source": [
        "SEED = 1729\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2a1bGhEqezU"
      },
      "source": [
        "def elapsed_time(start_time, end_time):\n",
        "    time_taken = end_time - start_time\n",
        "    elapsed_min = int(time_taken / 60)\n",
        "    elapsed_sec = int(time_taken - (elapsed_min * 60))\n",
        "    \n",
        "    return elapsed_min, elapsed_sec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpWzhs7pDoGy"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjaDSsB374eA"
      },
      "source": [
        "!python -m spacy download de\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eLO9mNA7ek8"
      },
      "source": [
        "de_model = spacy.load('de')\n",
        "en_model = spacy.load('en')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4WiPmda8FKC"
      },
      "source": [
        "def tokenize_en(sentence):\n",
        "    tokens = []\n",
        "    for token in de_model.tokenizer(sentence):\n",
        "        tokens.append(token.text.lower())\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "def tokenize_de(sentence):\n",
        "    tokens = []\n",
        "    for token in en_model.tokenizer(sentence):\n",
        "        tokens.append(token.text.lower())\n",
        "    \n",
        "    return tokens"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQuPoHbgQYXN",
        "outputId": "8416ebea-b6c7-4a6a-afce-1a99ea2129b1"
      },
      "source": [
        "print(tokenize_de(\"Hallo, wie geht's Ihnen?\"))\n",
        "print(tokenize_en(\"Hello, how are you?\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hallo', ',', 'wie', 'geht', \"'s\", 'ihnen', '?']\n",
            "['hello', ',', 'how', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfZMwzrO80F0"
      },
      "source": [
        "SOURCE_Field = Field(eos_token = '<eos>', init_token = '<sos>', lower = True, tokenize = tokenize_de)\n",
        "TARGET_Field = Field(eos_token = '<eos>', init_token = '<sos>', lower = True, tokenize = tokenize_en)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2zg77gL8-_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b471ff18-d26f-46ab-aa3a-6df0a2e0d13c"
      },
      "source": [
        "start_time = time.time()\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SOURCE_Field, TARGET_Field))\n",
        "end_time = time.time()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 866kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 166kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 158kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUqxnrubEolV",
        "outputId": "a341b7ce-22e3-42c2-a54d-92ffca7bf300"
      },
      "source": [
        "print(\"Time taken to generate train, valid and test datasets:\",elapsed_time(start_time, end_time))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time taken to generate train, valid and test datasets: (0, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd-olDi7qwje",
        "outputId": "eb64a267-de87-4c26-a254-03da3955e91e"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j89zk0IfSy83"
      },
      "source": [
        "SOURCE_Field.build_vocab(train_data, min_freq = 2)\n",
        "TARGET_Field.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAc9PnhLS4LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2aea05-b5e9-493b-8827-f8a15495aab9"
      },
      "source": [
        "print(f\"Vocabulary Size of Source Language: {len(SOURCE_Field.vocab)}\")\n",
        "print(f\"Vocabulary Size of Target Language: {len(TARGET_Field.vocab)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size of Source Language: 7873\n",
            "Vocabulary Size of Target Language: 5923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGJFzqc1S_pg"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZAYJAsonIuW"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "* The encoder is the first stage of Seq2Seq, and is a unidirectional two-layer RNN. (`num_layers = 2`)\n",
        "* The input given to it is the sequence of words (in the source language). [`input`] = `[time_steps, batch_size]`\n",
        "* The sequence needs to be converted to dense vectors to get their word representations. This is the actual input given (and the initial hidden state of RNN) to the RNN. (`embedded = self.dropout(self.embedding(input))`)  \n",
        "\n",
        "    `[embedded]` = `[time_steps, batch_size, embedding_dim]`\n",
        "    \n",
        "    \n",
        "* These embedded vectors are then passed inside the RNN, to get the output, and the final hidden state after going through each timestep ie. after it has gone through the whole sequence. (`output_rnn, states = self.rnn(embedded)`)\n",
        "\n",
        "    `[output_rnn] = [time_steps, batch_size, num_directions*hidden_dim]`\n",
        "\n",
        "    `[states] = (hidden, cell) = [num_layers*num_directions, batch_size, hidden_dim]`\n",
        "\n",
        "     Here `num_directions` is 1\n",
        "\n",
        "* This output will be used by the Decoder in the next stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBB-FsKcTDz_"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, enc_dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim, num_layers = num_layers, dropout = enc_dropout)\n",
        "        self.dropout = nn.Dropout(enc_dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # [input] = [time_steps, batch_size]\n",
        "        embedded = self.dropout(self.embedding(input))                          # [embedded] = [time_steps, batch_size, embedding_dim]\n",
        "        output_rnn, states = self.rnn(embedded)                                 # [output_rnn] = [time_steps, batch_size, num_directions*hidden_dim]   Here, number of directions is 1\n",
        "                                                                                # [states] = (hidden, cell) = [num_layers*num_directions, batch_size, hidden_dim]\n",
        "        return states\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0qbTur-nMXJ"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "* The Decoder is the second stage of Seq2Seq, and it also a unidirectional two-layer RNN. (`num_layers = 2`)\n",
        "* The input given to it is a word (in the target language) -  [`input`] = `[time_steps = 1, batch_size]` (and the initial hidden state of RNN)\n",
        "* The initial hidden state of the RNN will be the output hidden state of the Encoder RNN. ie. the context vector that is produced after it went through the sequence in the source language.\n",
        "* The word needs to be converted to a dense vector to get its word representation. This is the actual input given to the Decoder RNN. `[embedded]` = `[time_steps = 1, batch_size, embedding_dim]`\n",
        "    \n",
        "    `embedded = self.dropout(self.embedding(input))`  \n",
        "* These embedded vectors (along with the hidden state) of those timesteps are then passed inside the RNN, to get the output and the hidden state of the next cell. (`output_rnn, states = self.rnn(embedded)`)\n",
        "\n",
        "    `[output_rnn] = [time_steps, batch_size, num_directions*hidden_dim]`\n",
        "\n",
        "    `[states] = (hidden, cell) = [num_layers*num_directions, batch_size, hidden_dim]`\n",
        "\n",
        "     Here number of directions is 1\n",
        "* However this output needs to be passed into a Linear layer first to get the actual predicted word. (`output = self.fc(output).unsqueeze(0)`)\n",
        "\n",
        "    `[output]` = `[time_steps, batch_size, vocab_size]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BB8adYlUkpo"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dec_dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = vocab_size\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim, num_layers = num_layers, dropout = dec_dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dec_dropout)\n",
        "\n",
        "    def forward(self, input, states):\n",
        "        # input = [1, batch_size]\n",
        "        embedded = self.dropout(self.embedding(input))                          # [embedded] = [time_steps = 1, batch_size, embedding_dim]\n",
        "        output_rnn, states = self.rnn(embedded, states)                         # [output_rnn] = [time_steps = 1, batch_size, num_directions*hidden_dim]   Here, number of directions is 1\n",
        "        output = self.fc(output_rnn).unsqueeze(0)                               # [output] = [time_steps = 1, batch_size, vocab_size]\n",
        "\n",
        "        return output, states"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWbtifBQnQlZ"
      },
      "source": [
        "## Seq2Seq\n",
        "\n",
        "We now combine Encoder and Decoder to create the Seq2Seq model.\n",
        "\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "* As mentioned earlier, the encoder is the first component of the Seq2Seq model. Hence, the input to the Encoder is actually the input given to the Seq2Seq model: (`enc_input = input`)\n",
        "\n",
        "    `[enc_input] = [time_steps, batch_size]`\n",
        "\n",
        "* We obtain the output of the Encoder by passing this `enc_input` through the Encoder. (`enc_states = self.encoder(enc_input)`), which is the final hidden state after going through the whole sequence in the source language.\n",
        "* These output hidden states of the encoder will be the initial hidden state of the decoder. It is the context vector of the whole sequence in source language. (`dec_states = enc_states`)\n",
        "\n",
        "**Note:** The target vector (`target`) is the entire sequence in the target language. However, unlike in the encoder, we simply *can not* pass in the whole sequence all at once into the decoder. This is simply because we do not know the output sequence yet - this is what we have to predict! \n",
        "\n",
        "* Hence, we need to pass in the first word (and the initial hidden state ie. `dec_states`) into the decoder, get the output and hidden states, and then pass these again again to compute the output and hidden state of the next timestep. This is done until we reach the end of the sequence ie. until `time_steps`\n",
        "      dec_input = target[0].unsqueeze(0) \n",
        "      for t in range(1, time_steps):\n",
        "          output, dec_states = self.decoder(dec_input, dec_states) \n",
        "          output = output.squeeze()                        \n",
        "          predictions[t] = output.view(batch_size, self.decoder.output_dim)\n",
        "          if random.random() < teacher_forcing_ratio:\n",
        "              dec_input = target[t].unsqueeze(0)\n",
        "          else:\n",
        "              dec_input = output.argmax(1).unsqueeze(0)\n",
        "\n",
        "* **Teacher forcing ratio** is the use of the expected output instead of the actual output at a time step as the input for the next time step. ie. if `teacher_forcing_ratio` is 0.75, then the expected output is used as input 75% of the time.\n",
        "\n",
        "* Finally, we return the predictions, which is the predicted sequence in the target language. Note that we have returned `predictions[1:]` and not `predictions`. This because the first word in `predictions` is `<sos>` (start-of-sequence token)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6rtb2ZdXkhG"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def forward(self, input, target, teacher_forcing_ratio):\n",
        "        enc_input = input                                                                         # [enc_input] = [time_steps, batch_size]\n",
        "        enc_states = self.encoder(enc_input)\n",
        "        dec_states = enc_states\n",
        "        # [target] = [time_steps, batch_size]                                                 \n",
        "        time_steps = target.shape[0]\n",
        "        batch_size = target.shape[1]\n",
        "        predictions = torch.zeros(time_steps, batch_size, self.decoder.output_dim).to(device)     # [predictions] = [time_steps, batch_size, output_dim]\n",
        "        dec_input = target[0].unsqueeze(0)                                                        # [dec_input] = [1, batch_size] - First time_step is given as input\n",
        "        for t in range(1, time_steps):\n",
        "            output, dec_states = self.decoder(dec_input, dec_states) \n",
        "            output = output.squeeze()                        \n",
        "            predictions[t] = output.view(batch_size, self.decoder.output_dim)\n",
        "            if random.random() < teacher_forcing_ratio:\n",
        "                dec_input = target[t].unsqueeze(0)\n",
        "            else:\n",
        "                dec_input = output.argmax(1).unsqueeze(0)\n",
        "\n",
        "        return predictions[1:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSoM9JilnK8P"
      },
      "source": [
        "def epoch_train(train_iterator, model, criterion, optimizer, clip=1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for batch in train_iterator:\n",
        "        model.zero_grad()\n",
        "        batch_source = batch.src\n",
        "        batch_target = batch.trg\n",
        "        batch_outputs = model(batch_source, batch_target, teacher_forcing_ratio=0.5)\n",
        "        batch_outputs = batch_outputs.view(-1, batch_outputs.shape[-1])\n",
        "        batch_targets = batch_target[1:].view(-1)\n",
        "        batch_loss = criterion(batch_outputs, batch_targets.to(device))\n",
        "        batch_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        epoch_loss += batch_loss.item()\n",
        "\n",
        "    return epoch_loss/len(train_iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc0nXUTknY0x"
      },
      "source": [
        "def epoch_test(test_iterator, model, criterion):\n",
        "    model.eval()\n",
        "    eval_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iterator:\n",
        "            model.zero_grad()\n",
        "            batch_source = batch.src\n",
        "            batch_target = batch.trg\n",
        "            batch_outputs = model(batch_source, batch_target, 0)\n",
        "            batch_outputs = batch_outputs.view(-1, batch_outputs.shape[-1])\n",
        "            batch_targets = batch_target[1:].view(-1)\n",
        "            batch_loss = criterion(batch_outputs, batch_targets.to(device))\n",
        "            eval_loss += batch_loss.item()\n",
        "        \n",
        "        return eval_loss/len(test_iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D769Z-ADDsO5"
      },
      "source": [
        "# Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIAGDlkuqlRv"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), batch_size = BATCH_SIZE, device = device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CYgdvucqojH"
      },
      "source": [
        "CLIP = 1\n",
        "NUM_EPOCHS = 20\n",
        "LR = 1e-3\n",
        "HIDDEN_DIM = 512\n",
        "SRC_VOCAB_SIZE = len(SOURCE_Field.vocab)\n",
        "TRG_VOCAB_SIZE = len(TARGET_Field.vocab)\n",
        "EMBEDDING_DIM = 256\n",
        "NUM_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "PRINT_EVERY = 1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDfHAB6Jq6KO"
      },
      "source": [
        "target_padding_index = TARGET_Field.vocab.stoi[TARGET_Field.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = target_padding_index)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HskwpEgErAFc"
      },
      "source": [
        "encoder = Encoder(SRC_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, ENC_DROPOUT).to(device)\n",
        "decoder = Decoder(TRG_VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, DEC_DROPOUT).to(device)\n",
        "seq2seq = Seq2Seq(encoder, decoder).to(device)\n",
        "optimizer = optim.AdamW(seq2seq.parameters(), LR)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99lmBmZ7rCYL"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hULvKdUxrIkh",
        "outputId": "7e6f2a9b-7b91-40c0-c4b7-56829feecddb"
      },
      "source": [
        "seq2seq.apply(init_weights)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(7873, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(5923, 256)\n",
              "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
              "    (fc): Linear(in_features=512, out_features=5923, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9-MZwDErVal",
        "outputId": "a40143e5-6420-4157-b5b6-47e4dd9651c6"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(seq2seq):,} trainable parameters.')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,926,691 trainable parameters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMJobc37D39j"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dMBXEvWrYlw",
        "outputId": "4f079bdb-5297-44f4-a448-9363c29af0a5"
      },
      "source": [
        "print(f\"Learning Rate: {LR}, Hidden Dimensions: {HIDDEN_DIM}\",end=\"\\n\\n\")\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "start_time = time.time()\n",
        "print(\"Training started\",end=\"\\n\\n\")\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "\n",
        "    train_loss = epoch_train(train_iterator, seq2seq, criterion, optimizer, CLIP)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_loss = epoch_test(test_iterator, seq2seq, criterion)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    if epoch % PRINT_EVERY == 0:\n",
        "        end_time = time.time()\n",
        "        elapsed_min, elapsed_sec = elapsed_time(start_time, end_time)\n",
        "        print(f\"Epoch {epoch} | Time taken since start of training: {elapsed_min}min {elapsed_sec}sec\")\n",
        "        print(f\"Training Loss: {train_loss:.4f} | Validation Loss: {valid_loss:.4f}\")\n",
        "        print(f\"Training PPL: {math.exp(train_loss):.4f} | Validation PPL: {math.exp(valid_loss):.4f}\")\n",
        "        print(\"\")\n",
        "\n",
        "print(\"Training finished\", end=\"\\n\\n\")\n",
        "elapsed_min, elapsed_sec = elapsed_time(start_time, end_time)\n",
        "print(f\"Total time taken for training: {elapsed_min}min {elapsed_sec}sec\")\n",
        "elapsed_min, elapsed_sec = elapsed_time(start_time/NUM_EPOCHS, end_time/NUM_EPOCHS)\n",
        "print(f\"Average time taken per epoch: {elapsed_min}min {elapsed_sec}sec\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning Rate: 0.001, Hidden Dimensions: 512\n",
            "\n",
            "Training started\n",
            "\n",
            "Epoch 1 | Time taken since start of training: 0min 34sec\n",
            "Training Loss: 5.0368 | Validation Loss: 5.0542\n",
            "Training PPL: 153.9705 | Validation PPL: 156.6861\n",
            "\n",
            "Epoch 2 | Time taken since start of training: 1min 10sec\n",
            "Training Loss: 4.4383 | Validation Loss: 4.6751\n",
            "Training PPL: 84.6349 | Validation PPL: 107.2385\n",
            "\n",
            "Epoch 3 | Time taken since start of training: 1min 46sec\n",
            "Training Loss: 4.1070 | Validation Loss: 4.4943\n",
            "Training PPL: 60.7646 | Validation PPL: 89.5088\n",
            "\n",
            "Epoch 4 | Time taken since start of training: 2min 21sec\n",
            "Training Loss: 3.8802 | Validation Loss: 4.3706\n",
            "Training PPL: 48.4345 | Validation PPL: 79.0939\n",
            "\n",
            "Epoch 5 | Time taken since start of training: 2min 57sec\n",
            "Training Loss: 3.7327 | Validation Loss: 4.2455\n",
            "Training PPL: 41.7922 | Validation PPL: 69.7912\n",
            "\n",
            "Epoch 6 | Time taken since start of training: 3min 32sec\n",
            "Training Loss: 3.5700 | Validation Loss: 4.1160\n",
            "Training PPL: 35.5178 | Validation PPL: 61.3135\n",
            "\n",
            "Epoch 7 | Time taken since start of training: 4min 8sec\n",
            "Training Loss: 3.4132 | Validation Loss: 3.9525\n",
            "Training PPL: 30.3626 | Validation PPL: 52.0643\n",
            "\n",
            "Epoch 8 | Time taken since start of training: 4min 43sec\n",
            "Training Loss: 3.2908 | Validation Loss: 3.9291\n",
            "Training PPL: 26.8645 | Validation PPL: 50.8593\n",
            "\n",
            "Epoch 9 | Time taken since start of training: 5min 19sec\n",
            "Training Loss: 3.1456 | Validation Loss: 3.7784\n",
            "Training PPL: 23.2328 | Validation PPL: 43.7470\n",
            "\n",
            "Epoch 10 | Time taken since start of training: 5min 54sec\n",
            "Training Loss: 3.0241 | Validation Loss: 3.7232\n",
            "Training PPL: 20.5747 | Validation PPL: 41.3985\n",
            "\n",
            "Epoch 11 | Time taken since start of training: 6min 30sec\n",
            "Training Loss: 2.9238 | Validation Loss: 3.7087\n",
            "Training PPL: 18.6113 | Validation PPL: 40.8025\n",
            "\n",
            "Epoch 12 | Time taken since start of training: 7min 5sec\n",
            "Training Loss: 2.7989 | Validation Loss: 3.6460\n",
            "Training PPL: 16.4274 | Validation PPL: 38.3223\n",
            "\n",
            "Epoch 13 | Time taken since start of training: 7min 41sec\n",
            "Training Loss: 2.6798 | Validation Loss: 3.6680\n",
            "Training PPL: 14.5817 | Validation PPL: 39.1736\n",
            "\n",
            "Epoch 14 | Time taken since start of training: 8min 17sec\n",
            "Training Loss: 2.6183 | Validation Loss: 3.5958\n",
            "Training PPL: 13.7127 | Validation PPL: 36.4453\n",
            "\n",
            "Epoch 15 | Time taken since start of training: 8min 52sec\n",
            "Training Loss: 2.5127 | Validation Loss: 3.5510\n",
            "Training PPL: 12.3381 | Validation PPL: 34.8486\n",
            "\n",
            "Epoch 16 | Time taken since start of training: 9min 28sec\n",
            "Training Loss: 2.4476 | Validation Loss: 3.5437\n",
            "Training PPL: 11.5605 | Validation PPL: 34.5947\n",
            "\n",
            "Epoch 17 | Time taken since start of training: 10min 3sec\n",
            "Training Loss: 2.3949 | Validation Loss: 3.5207\n",
            "Training PPL: 10.9668 | Validation PPL: 33.8065\n",
            "\n",
            "Epoch 18 | Time taken since start of training: 10min 39sec\n",
            "Training Loss: 2.2848 | Validation Loss: 3.5818\n",
            "Training PPL: 9.8238 | Validation PPL: 35.9394\n",
            "\n",
            "Epoch 19 | Time taken since start of training: 11min 14sec\n",
            "Training Loss: 2.2456 | Validation Loss: 3.5362\n",
            "Training PPL: 9.4459 | Validation PPL: 34.3367\n",
            "\n",
            "Epoch 20 | Time taken since start of training: 11min 49sec\n",
            "Training Loss: 2.1428 | Validation Loss: 3.5904\n",
            "Training PPL: 8.5235 | Validation PPL: 36.2474\n",
            "\n",
            "Training finished\n",
            "\n",
            "Total time taken for training: 11min 49sec\n",
            "Average time taken per epoch: 0min 35sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGiYVb2DyhxA"
      },
      "source": [
        "torch.save(seq2seq.state_dict(), MODEL_STORE_PATH + \".pth\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "b0lHdHbuvO_2",
        "outputId": "fda56e07-45b4-455e-a57c-554900276f56"
      },
      "source": [
        "plt.title(\"Seq2Seq: Learning Curves\")\n",
        "plt.xlabel(\"Number of Epochs\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "plt.plot(train_losses, label = \"Training Loss\")\n",
        "plt.plot(valid_losses, label= \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig(MODEL_STORE_PATH + \".jpeg\")\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8ypXaNJ1iLo"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hG6m6_qsJKS",
        "outputId": "581b8095-1244-4523-cf16-3ea56f31831d"
      },
      "source": [
        "seq2seq.load_state_dict(torch.load(MODEL_STORE_PATH + \".pth\"))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5jMPYP2Ged",
        "outputId": "7fe15f1d-f281-47d8-e021-200d52a20c90"
      },
      "source": [
        "seq2seq.eval()\n",
        "test_loss = epoch_test(test_iterator, seq2seq, criterion)\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test PPL: {math.exp(test_loss):.4f}\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 3.5904 | Test PPL: 36.2474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJJbfSHN2eoX"
      },
      "source": [
        "def getInputTensor(sentence, src_field):\n",
        "    tokens = [src_field.init_token] + [token for token in sentence] + [src_field.eos_token]\n",
        "    seq_len = len(tokens)\n",
        "    input_tensor = torch.LongTensor([src_field.vocab.stoi[token] for token in tokens]).to(device)\n",
        "    return input_tensor.view(seq_len, 1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjFpIdSP2PzW"
      },
      "source": [
        "def Translate(src_sentence, src_field, trg_field, model):\n",
        "    input_tensor = getInputTensor(src_sentence, src_field)\n",
        "    max_len = 4*input_tensor.shape[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_states = model.encoder(input_tensor)\n",
        "    dec_states = enc_states\n",
        "    sos_id = trg_field.vocab.stoi[trg_field.init_token]\n",
        "    eos_id = trg_field.vocab.stoi[trg_field.eos_token]\n",
        "    predicts = [sos_id]\n",
        "    len = 1\n",
        "    while len < max_len:\n",
        "        input = torch.LongTensor([predicts[-1]]).view((1, 1)).to(device)\n",
        "        with torch.no_grad():\n",
        "            output, dec_states = model.decoder(input, dec_states)\n",
        "        output = output.squeeze()\n",
        "        output = output.view(-1, model.decoder.output_dim)\n",
        "        predicts.append(output.argmax(-1).item())\n",
        "        len += 1\n",
        "        if predicts[-1] == eos_id:\n",
        "            break\n",
        "    sentence = [trg_field.vocab.itos[id] for id in predicts[1:]]\n",
        "    return sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLvNkxeC2UDz",
        "outputId": "e81799ff-f594-47bc-f32b-6925f4e3c74a"
      },
      "source": [
        "idx = int(random.random() * len(test_data.examples))\n",
        "example = test_data.examples[idx]\n",
        "src_sentence = example.src\n",
        "trg_sentence = example.trg\n",
        "print(\"German Sentence: \", ' '.join(src_sentence))\n",
        "translation = Translate(src_sentence, SOURCE_Field, TARGET_Field, seq2seq)\n",
        "print(\"Predicted Translation: \", ' '.join(translation[:-1]))\n",
        "print(\"Actual Translation: \", ' '.join(trg_sentence))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "German Sentence:  ein kleines mädchen schiebt seinen roller über eine wiese mit bäumen .\n",
            "Predicted Translation:  a little girl is riding a tricycle in a field of grass .\n",
            "Actual Translation:  a little girl is pushing her scooter through a grassy tree lined field .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO7J77lI2x5V"
      },
      "source": [
        "# BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2d2PQv_2WOI"
      },
      "source": [
        "def Calculate_BLEU(data, src_field, trg_field, model):\n",
        "    trgs = []\n",
        "    predicted_trgs = []\n",
        "    for i in range(len(data.examples)):\n",
        "        src_sentence = vars(data[i])['src']\n",
        "        trg_sentence = vars(data[i])['trg']\n",
        "        try:                                # Sometimes(rarely) CUDA throws a \"Device side assert triggered\" error. So, just to avoid restarting runtime.\n",
        "            predicted_trg = Translate(src_sentence, src_field, trg_field, model)\n",
        "            predicted_trgs.append(predicted_trg[:-1])\n",
        "            trgs.append([trg_sentence])\n",
        "        except:\n",
        "            pass\n",
        "    return bleu_score(predicted_trgs, trgs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f_V90wK20nx",
        "outputId": "c44ec0b0-c0bd-4fdd-d7e0-5240fc4925e8"
      },
      "source": [
        "bleu_score_test = Calculate_BLEU(test_data, SOURCE_Field, TARGET_Field, seq2seq)\n",
        "print(f\"BLEU score on Testing Data: {bleu_score_test*100:.2f}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score on Testing Data: 20.59\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}